{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Applied Machine Learning Coursework**\n",
        "\n",
        "In the first cell of code data is read from csv files, pre-processed, cleaned and tranformed. Then the data is ready for splitting into training and testing data."
      ],
      "metadata": {
        "id": "PsWEc2q9LAlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "#dataset uploaded to session storage and then read through pandas read csv function.\n",
        "#Session storage expires after the window is closed.\n",
        "#Kindly upload dataset files into session storage before executing the code.\n",
        "data1 = pd.read_csv(\"processed_reviews_split_surnamesABCD_minimal.csv\")\n",
        "data2 = pd.read_csv(\"processed_reviews_split_surnamesEFGH_minimal.csv\")\n",
        "data3 = pd.read_csv(\"processed_reviews_split_surnamesIJKLM_minimal.csv\")\n",
        "data4 = pd.read_csv(\"processed_reviews_split_surnamesNOPQ_minimal.csv\")\n",
        "data5 = pd.read_csv(\"processed_reviews_split_surnamesRSTU_minimal.csv\")\n",
        "data6 = pd.read_csv(\"processed_reviews_split_surnamesVWXYZ_minimal.csv\")\n",
        "data = pd.concat([data1, data2, data3, data4, data5, data5, data6], ignore_index=True)\n",
        "data = data.dropna()\n",
        "data = data.drop_duplicates()\n",
        "print(data.shape)\n",
        "print(data['acceptance_status'].value_counts())\n",
        "def textCleaning(text):\n",
        "    remove_punctuation = [char for char in text if char not in string.punctuation]\n",
        "    remove_punctuation = ''.join(remove_punctuation)\n",
        "    return [word for word in remove_punctuation.split() if word.lower() not in stopwords.words(\"english\")]\n",
        "data.iloc[:,1].apply(textCleaning)\n",
        "bowTransformer = CountVectorizer(analyzer=textCleaning).fit(data['text'])\n",
        "bowTransformer.vocabulary_\n",
        "textBow = bowTransformer.transform(data['text'])\n",
        "tfidftranformer = TfidfTransformer().fit(textBow)\n",
        "print(tfidftranformer)\n",
        "\n",
        "textTfidf = tfidftranformer.transform(textBow)\n",
        "print(textTfidf)\n",
        "print(textTfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DiqdbksYrho_",
        "outputId": "489f12c6-68f9-4884-ead4-41c8493b0186"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "(19574, 5)\n",
            "Reject    11795\n",
            "Accept     7779\n",
            "Name: acceptance_status, dtype: int64\n",
            "TfidfTransformer()\n",
            "  (0, 69765)\t0.015410668210625506\n",
            "  (0, 69676)\t0.01492117668272231\n",
            "  (0, 69319)\t0.038042075437836935\n",
            "  (0, 69235)\t0.08228419584020055\n",
            "  (0, 69213)\t0.09479505927603965\n",
            "  (0, 69185)\t0.0334287529008592\n",
            "  (0, 68580)\t0.051870991493859216\n",
            "  (0, 68197)\t0.016487304682780198\n",
            "  (0, 68190)\t0.017312986743635444\n",
            "  (0, 66704)\t0.05844813408469927\n",
            "  (0, 66551)\t0.04635818097833611\n",
            "  (0, 66117)\t0.0664693132190417\n",
            "  (0, 66018)\t0.091355246632686\n",
            "  (0, 65683)\t0.07490169035869262\n",
            "  (0, 65655)\t0.03468308778216253\n",
            "  (0, 65418)\t0.08382623572657076\n",
            "  (0, 65097)\t0.038928721613849915\n",
            "  (0, 65037)\t0.05147948208754048\n",
            "  (0, 64821)\t0.03031747985193076\n",
            "  (0, 64680)\t0.0438608189463233\n",
            "  (0, 64444)\t0.027030062434715788\n",
            "  (0, 63930)\t0.08878601668212978\n",
            "  (0, 63405)\t0.04118617858301399\n",
            "  (0, 63245)\t0.08878601668212978\n",
            "  (0, 62957)\t0.029189039102643262\n",
            "  :\t:\n",
            "  (19573, 16766)\t0.06338652843788299\n",
            "  (19573, 16765)\t0.05690281148174211\n",
            "  (19573, 16038)\t0.08897228295782349\n",
            "  (19573, 15993)\t0.16865345251061697\n",
            "  (19573, 13243)\t0.12118039456057517\n",
            "  (19573, 13098)\t0.316932642189415\n",
            "  (19573, 12436)\t0.0612847493680784\n",
            "  (19573, 11402)\t0.028276232573125094\n",
            "  (19573, 11351)\t0.0712757628248064\n",
            "  (19573, 11332)\t0.03560421773642989\n",
            "  (19573, 10042)\t0.0743357127985805\n",
            "  (19573, 9406)\t0.07085269992353584\n",
            "  (19573, 8244)\t0.07171947093894349\n",
            "  (19573, 8232)\t0.0649721351666239\n",
            "  (19573, 6872)\t0.13222603967951524\n",
            "  (19573, 6179)\t0.07967837504664484\n",
            "  (19573, 4548)\t0.23806071935043688\n",
            "  (19573, 2477)\t0.09300992061242694\n",
            "  (19573, 2473)\t0.0743357127985805\n",
            "  (19573, 2437)\t0.022926522211555764\n",
            "  (19573, 1258)\t0.028703490263931805\n",
            "  (19573, 1017)\t0.05957868773448905\n",
            "  (19573, 551)\t0.17794456591564697\n",
            "  (19573, 506)\t0.038746827281995216\n",
            "  (19573, 372)\t0.08005241344000397\n",
            "(19574, 73828)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the second cell of code data is splitted into training and testing subsets. Data is fitted into Multinomial naive bayes model and prediction is made using the testing data. lastly accuracy, classification report and confusion matrix are printed."
      ],
      "metadata": {
        "id": "xWf6y3IXLvFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(textTfidf, data['acceptance_status'], test_size = 0.25, random_state = 0)\n",
        "modelNB = MultinomialNB().fit(X_train, y_train)\n",
        "prediction = modelNB.predict(X_test)\n",
        "print(\"Naive Bayes acceptance status prediction: \\n\", prediction)\n",
        "print(\"The accuracy score of Naive Bayes acceptance status prediction is: \\n\",accuracy_score(y_test, prediction))\n",
        "print(classification_report(y_test, prediction))\n",
        "\n",
        "print(confusion_matrix(y_test, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAdU-qne3pyw",
        "outputId": "0ebabf42-94ba-49a8-d886-c8d09fbcc23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes acceptance status prediction: \n",
            " ['Reject' 'Reject' 'Reject' ... 'Reject' 'Reject' 'Reject']\n",
            "The accuracy score of Naive Bayes acceptance status prediction is: \n",
            " 0.6697997548017981\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Accept       1.00      0.15      0.26      1903\n",
            "      Reject       0.65      1.00      0.79      2991\n",
            "\n",
            "    accuracy                           0.67      4894\n",
            "   macro avg       0.82      0.58      0.52      4894\n",
            "weighted avg       0.79      0.67      0.58      4894\n",
            "\n",
            "[[ 287 1616]\n",
            " [   0 2991]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the third cell of code data is splitted into training and testing subsets. Here the label/target is review score. Data is fitted into Multinomial naive bayes model and prediction is made using the testing data. lastly accuracy, classification report and confusion matrix are printed."
      ],
      "metadata": {
        "id": "n5qEEVtJMYSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(textTfidf, data['review_score'], test_size = 0.25, random_state = 0)\n",
        "modelNB = MultinomialNB().fit(X_train, y_train)\n",
        "prediction = modelNB.predict(X_test)\n",
        "print(\"Naive Bayes review score prediction: \\n\", prediction)\n",
        "print(\"The accuracy score of Naive Bayes review score prediction is: \\n\",accuracy_score(y_test, prediction))\n",
        "print(classification_report(y_test, prediction))\n",
        "print(confusion_matrix(y_test, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebVlmbCE3r8R",
        "outputId": "a9fce8f7-c316-43cb-915b-7d673a2854a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes review score prediction: \n",
            " [6. 6. 6. ... 6. 6. 5.]\n",
            "The accuracy score of Naive Bayes review score prediction is: \n",
            " 0.40375970576215775\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.00      0.00      0.00       131\n",
            "         1.0       0.00      0.00      0.00        12\n",
            "         2.0       0.00      0.00      0.00        93\n",
            "         3.0       0.00      0.00      0.00       419\n",
            "         4.0       0.61      0.34      0.44       928\n",
            "         5.0       0.45      0.56      0.50       999\n",
            "         6.0       0.33      0.88      0.48      1098\n",
            "         7.0       0.67      0.15      0.25       878\n",
            "         8.0       0.00      0.00      0.00       252\n",
            "         9.0       0.00      0.00      0.00        76\n",
            "        10.0       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.40      4894\n",
            "   macro avg       0.19      0.18      0.15      4894\n",
            "weighted avg       0.40      0.40      0.34      4894\n",
            "\n",
            "[[  0   0   0   0  17  35  68  11   0   0   0]\n",
            " [  0   0   0   0   2   4   6   0   0   0   0]\n",
            " [  0   0   0   0  21  30  41   1   0   0   0]\n",
            " [  0   0   0   0  78 124 215   2   0   0   0]\n",
            " [  0   0   0   0 319 222 383   4   0   0   0]\n",
            " [  0   0   0   0  43 557 391   8   0   0   0]\n",
            " [  0   0   0   0  14  96 967  21   0   0   0]\n",
            " [  0   0   0   0  24 126 595 133   0   0   0]\n",
            " [  0   0   0   0   4  22 213  13   0   0   0]\n",
            " [  0   0   0   0   1  13  55   7   0   0   0]\n",
            " [  0   0   0   0   0   2   6   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the forth cell of code data is splitted into training and testing subsets. Data is fitted into Logistic regression model and prediction is made using the testing data. lastly accuracy, classification report and confusion matrix are printed."
      ],
      "metadata": {
        "id": "264Vh_P8MsB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(textTfidf, data['acceptance_status'], test_size = 0.25, random_state = 0)\n",
        "modelLR = LogisticRegression().fit(X_train, y_train)\n",
        "prediction = modelLR.predict(X_test)\n",
        "print(\"Logistic Regression acceptance status prediction: \\n\", prediction)\n",
        "print(\"The accuracy score of Logistic Regression acceptance status prediction is: \\n\",accuracy_score(y_test, prediction))\n",
        "print(classification_report(y_test, prediction))\n",
        "print(confusion_matrix(y_test, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9wwNgkM3wHn",
        "outputId": "9dc51c35-8325-49f9-cd5e-dc3b0502ebe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression acceptance status prediction: \n",
            " ['Reject' 'Reject' 'Reject' ... 'Accept' 'Accept' 'Reject']\n",
            "The accuracy score of Logistic Regression acceptance status prediction is: \n",
            " 0.8872088271352677\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Accept       0.93      0.77      0.84      1903\n",
            "      Reject       0.87      0.96      0.91      2991\n",
            "\n",
            "    accuracy                           0.89      4894\n",
            "   macro avg       0.90      0.87      0.88      4894\n",
            "weighted avg       0.89      0.89      0.88      4894\n",
            "\n",
            "[[1463  440]\n",
            " [ 112 2879]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the fifth cell of code data is splitted into training and testing subsets. Here the label/target is confidence score Data is fitted into Multinomial naive bayes model and prediction is made using the testing data. lastly accuracy, classification report and confusion matrix are printed."
      ],
      "metadata": {
        "id": "fR3bAaTvM4y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(textTfidf, data['confidence_score'], test_size = 0.25, random_state = 0)\n",
        "modelLR = LogisticRegression().fit(X_train, y_train)\n",
        "prediction = modelLR.predict(X_test)\n",
        "print(\"Logistic Regression confidence score prediction: \\n\", prediction)\n",
        "print(\"The accuracy score of Logistic Regression confidence_score prediction is: \\n\",accuracy_score(y_test, prediction))\n",
        "print(classification_report(y_test, prediction))\n",
        "print(confusion_matrix(y_test, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DbrXw4H30CO",
        "outputId": "629d3a35-7d74-4f19-a59c-af5413d94306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression confidence score prediction: \n",
            " [4. 4. 4. ... 4. 5. 4.]\n",
            "The accuracy score of Logistic Regression confidence_score prediction is: \n",
            " 0.6348590110339191\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00        44\n",
            "         2.0       0.91      0.04      0.07       256\n",
            "         3.0       0.67      0.43      0.52      1261\n",
            "         4.0       0.61      0.94      0.74      2455\n",
            "         5.0       0.85      0.27      0.41       878\n",
            "\n",
            "    accuracy                           0.63      4894\n",
            "   macro avg       0.61      0.34      0.35      4894\n",
            "weighted avg       0.68      0.63      0.59      4894\n",
            "\n",
            "[[   0    0   17   26    1]\n",
            " [   0   10   76  167    3]\n",
            " [   0    0  546  697   18]\n",
            " [   0    1  122 2312   20]\n",
            " [   0    0   60  579  239]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}